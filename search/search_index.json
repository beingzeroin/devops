{
    "docs": [
        {
            "location": "/", 
            "text": "DevOps Lab\n\n\nA collection of Docker and Vagrant images mainly to provision distributed systems for local development, learning purposes and quick prototyping.\n\n\nDocumentations\n\n\n\n\nAnsible\n\n\nHadoop\n\n\nCassandra\n\n\nZookeeper\n\n\nKafka\n\n\nOther", 
            "title": "Home"
        }, 
        {
            "location": "/#devops-lab", 
            "text": "A collection of Docker and Vagrant images mainly to provision distributed systems for local development, learning purposes and quick prototyping.  Documentations   Ansible  Hadoop  Cassandra  Zookeeper  Kafka  Other", 
            "title": "DevOps Lab"
        }, 
        {
            "location": "/ansible/", 
            "text": "Ansible\n\n\nAnsible is an open source automation platform that can help with config management, deployment and task automation.\n\n\nDocumentation\n\n\n\n\nAnsible\n\n\nTutorial\n\n\nPlaybook example\n\n\n\n\nRequirement\n\n\n\n\nVagrant\n\n\nVirtualBox\n\n\n\n\nThe following guide explains how to provision Ansible locally and play with it. Checkout the \nVagrantfile\n and the Vagrant \nguide\n for more details.\n\n\nDirectory structure\n\n\nAll the commands are executed in this directory \ncd ansible\n\n\nansible/\n\u251c\u2500\u2500 .share\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ssh\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ansible_rsa\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 ansible_rsa.pub\n\u251c\u2500\u2500 Vagrantfile\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 group_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 host_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hosts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 roles\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 defaults\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 handlers\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 motd.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 motd\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 vars\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 site.yml\n\u251c\u2500\u2500 setup_ansible.sh\n\u2514\u2500\u2500 setup_share.sh\n\n\n\n\nSetup\n\n\nThe first time \nonly\n, you have to setup the shared folders and generate the ssh key needed by ansible to access all nodes executing\n\n\n./setup_share.sh\n\n\n\n\nFrom now on start the boxes with\n\n\nvagrant up\n\n\n\n\nNote that the first time it could take a while\n\n\nVerify status of the boxes with\n\n\nvagrant status\n\n\n\n\nVerify access to the boxes with\n\n\nvagrant ssh ansible\nvagrant ssh node-1\n\n\n\n\nFrom inside the boxes you should be able to communicate with the others\n\n\nping ansible.local\nping ip-192-168-100-11.local\nping 192.168.100.12\n\n\n\n\nThe following paths are shared with the boxes\n\n\n\n\n/vagrant\n provision-tool\n\n\n/local\n host $HOME\n\n\n/ansible\n data \n(ansible only)\n\n\n/data\n .share \n(node only)\n\n\n\n\nAd-Hoc Commands\n\n\nAccess the ansible box with\n\n\nvagrant ssh ansible\n\n\n\n\nBelow a list of examples\n\n\n\n# ping all nodes (default inventory /etc/ansible/hosts)\nansible all -m ping\nansible ansible -m ping\nansible cluster -m ping\n\n# ping all nodes (specify inventory)\nansible all -i \n/vagrant/data/hosts\n -m ping\n\n# gathering facts\nansible all -m setup\nansible ansible -m setup\n\n# specify host and user\nansible ip-192-168-100-11.local -m ping -u vagrant\n\n# execute command\nansible all -a \n/bin/echo hello\n\nansible all -a \nuptime\n\nansible all -a \n/bin/date\n\n# do NOT reboot vagrant through ansible (use vagrant reload)\nansible cluster -a \n/sbin/reboot\n --become\n\n# shell module\nansible all -m shell -a \npwd\n\n# be carefull to quotes\nansible all -m shell -a 'echo $HOME'\n\n# update \n upgrade\nansible all -m apt -a \nupdate_cache=yes upgrade=dist\n --become\n# restart after upgrade\nvagrant reload\n# install package\nansible all -m apt -a \nname=tree state=present\n --become\n\n\n\n\nPlaybooks\n\n\nAccess the ansible box with\n\n\nvagrant ssh ansible\n\n\n\n\nBelow a list of examples\n\n\n# test uptime on all node\nansible-playbook /ansible/site.yml --tags=test --verbose\n\n# update \n upgrade only cluster nodes\nansible-playbook /ansible/site.yml -t package --skip-tags=java --verbose\n\n# install packages on cluster nodes\nansible-playbook /ansible/site.yml -t package --verbose\n\n# run common task on cluster node\nansible-playbook /ansible/site.yml -t common\n\n# setup docker\nansible-playbook /ansible/site.yml -t docker\n# test docker\nvagrant ssh node-1\nsudo -i -u docker\ndocker ps -a\n\n# custom banner\nansible-playbook /ansible/site.yml -t motd\n\n# setup all infrastructure at once\nansible-playbook /ansible/site.yml\n\n# dry run\nansible-playbook -i /ansible/hosts /ansible/site.yml --check --diff", 
            "title": "Ansible"
        }, 
        {
            "location": "/ansible/#ansible", 
            "text": "Ansible is an open source automation platform that can help with config management, deployment and task automation.  Documentation   Ansible  Tutorial  Playbook example   Requirement   Vagrant  VirtualBox   The following guide explains how to provision Ansible locally and play with it. Checkout the  Vagrantfile  and the Vagrant  guide  for more details.", 
            "title": "Ansible"
        }, 
        {
            "location": "/ansible/#directory-structure", 
            "text": "All the commands are executed in this directory  cd ansible  ansible/\n\u251c\u2500\u2500 .share\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ssh\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ansible_rsa\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 ansible_rsa.pub\n\u251c\u2500\u2500 Vagrantfile\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 group_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 host_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hosts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 roles\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 defaults\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 handlers\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 motd.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 motd\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 vars\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 site.yml\n\u251c\u2500\u2500 setup_ansible.sh\n\u2514\u2500\u2500 setup_share.sh", 
            "title": "Directory structure"
        }, 
        {
            "location": "/ansible/#setup", 
            "text": "The first time  only , you have to setup the shared folders and generate the ssh key needed by ansible to access all nodes executing  ./setup_share.sh  From now on start the boxes with  vagrant up  Note that the first time it could take a while  Verify status of the boxes with  vagrant status  Verify access to the boxes with  vagrant ssh ansible\nvagrant ssh node-1  From inside the boxes you should be able to communicate with the others  ping ansible.local\nping ip-192-168-100-11.local\nping 192.168.100.12  The following paths are shared with the boxes   /vagrant  provision-tool  /local  host $HOME  /ansible  data  (ansible only)  /data  .share  (node only)", 
            "title": "Setup"
        }, 
        {
            "location": "/ansible/#ad-hoc-commands", 
            "text": "Access the ansible box with  vagrant ssh ansible  Below a list of examples  \n# ping all nodes (default inventory /etc/ansible/hosts)\nansible all -m ping\nansible ansible -m ping\nansible cluster -m ping\n\n# ping all nodes (specify inventory)\nansible all -i  /vagrant/data/hosts  -m ping\n\n# gathering facts\nansible all -m setup\nansible ansible -m setup\n\n# specify host and user\nansible ip-192-168-100-11.local -m ping -u vagrant\n\n# execute command\nansible all -a  /bin/echo hello \nansible all -a  uptime \nansible all -a  /bin/date \n# do NOT reboot vagrant through ansible (use vagrant reload)\nansible cluster -a  /sbin/reboot  --become\n\n# shell module\nansible all -m shell -a  pwd \n# be carefull to quotes\nansible all -m shell -a 'echo $HOME'\n\n# update   upgrade\nansible all -m apt -a  update_cache=yes upgrade=dist  --become\n# restart after upgrade\nvagrant reload\n# install package\nansible all -m apt -a  name=tree state=present  --become", 
            "title": "Ad-Hoc Commands"
        }, 
        {
            "location": "/ansible/#playbooks", 
            "text": "Access the ansible box with  vagrant ssh ansible  Below a list of examples  # test uptime on all node\nansible-playbook /ansible/site.yml --tags=test --verbose\n\n# update   upgrade only cluster nodes\nansible-playbook /ansible/site.yml -t package --skip-tags=java --verbose\n\n# install packages on cluster nodes\nansible-playbook /ansible/site.yml -t package --verbose\n\n# run common task on cluster node\nansible-playbook /ansible/site.yml -t common\n\n# setup docker\nansible-playbook /ansible/site.yml -t docker\n# test docker\nvagrant ssh node-1\nsudo -i -u docker\ndocker ps -a\n\n# custom banner\nansible-playbook /ansible/site.yml -t motd\n\n# setup all infrastructure at once\nansible-playbook /ansible/site.yml\n\n# dry run\nansible-playbook -i /ansible/hosts /ansible/site.yml --check --diff", 
            "title": "Playbooks"
        }, 
        {
            "location": "/hadoop/", 
            "text": "Hadoop\n\n\nThe following guide explains how to provision a Multi Node Hadoop Cluster locally and play with it. Checkout the \nVagrantfile\n and the Vagrant \nguide\n for more details.\n\n\nDirectory structure\n\n\nAll the commands are executed in this directory \ncd hadoop\n\n\nTODO\n\n\n\n\nSetup\n\n\nRequirements\n\n\n\n\nVagrant\n\n\nVirtualBox\n\n\n\n\nImport the script\n\n\nsource vagrant_hadoop.sh\n\n\n\n\nCreate and start a Multi Node Hadoop Cluster\n\n\nhadoop-start\n\n\n\n\nNote that the first time it could take a while\n\n\nAccess the cluster via ssh, check also the \n/etc/hosts\n file\n\n\nvagrant ssh master\nssh hadoop@172.16.0.10 -i .data/hadoop_rsa\n\n# 3 nodes\nvagrant ssh node-1\nssh hadoop@172.16.0.101 -i .data/hadoop_rsa\n\n\n\n\nDestroy the cluster\n\n\nhadoop-destroy\n\n\n\n\nUseful paths\n\n\n# data\n/var/hadoop\n# logs\n/var/hadoop/log\n# (local) config\n/usr/local/hadoop/etc/hadoop\n# (hdfs) map-reduce history\n/mr-history/history/done_intermediate/hadoop\n# (hdfs) aggregated app logs\n/yarn/app/hadoop/logs/application_XXX\n\n\n\n\nWeb UI links\n\n\n\n\nNameNode: \nhttp://namenode:50070\n\n\nNameNode metrics: \nhttp://namenode:50070/jmx\n\n\nResourceManager: \nhttp://resource-manager:8088\n\n\nLog Level: \nhttp://resource-manager:8088/logLevel\n\n\nJVM stack traces: \nhttp://resource-manager:8088/stacks\n\n\nWeb Application Proxy Server: \nhttp://web-proxy:8100/proxy/application_XXX_0000\n\n\nMapReduce Job History Server: \nhttp://history:19888\n\n\nDataNode/NodeManager (1): \nhttp://node-1:8042/node\n\n\nDataNode/NodeManager (2): \nhttp://node-2:8042/node\n\n\nDataNode/NodeManager (3): \nhttp://node-3:8042/node\n\n\n\n\nHDFS and MapReduce\n\n\n\n\nHDFS\n is a distributed file system that provides high-throughput access to application data\n\n\nYARN\n is a framework for job scheduling and cluster resource management\n\n\nMapReduce\n is a YARN-based system for parallel processing of large data sets\n\n\n\n\nDocumentation\n\n\n\n\nHadoop v2.7.5\n\n\nUntangling Apache Hadoop YARN\n series\n\n\n\n\nHDFS Admin\n\n\n# filesystem statistics\nhdfs dfsadmin -report\n\n# filesystem check\nhdfs fsck /\n\n\n\n\nMapReduce WordCount Job\n\n\n# create base directory using hdfs\nhdfs dfs -mkdir -p /user/ubuntu\n\n# create example directory\nhadoop fs -mkdir -p /user/ubuntu/word-count/input\n\n# list directory\nhadoop fs -ls -h -R /\nhadoop fs -ls -h -R /user/ubuntu\n\n# create sample files\necho \nHello World Bye World\n \n file01\necho \nHello Hadoop Goodbye Hadoop\n \n file02\n\n# copy from local to hdfs\nhadoop fs -copyFromLocal file01 /user/ubuntu/word-count/input\nhadoop fs -put file02 /user/ubuntu/word-count/input\n\n# verify copied files\nhadoop fs -ls -h -R /user/ubuntu\nhadoop fs -cat /user/ubuntu/word-count/input/file01\nhadoop fs -cat /user/ubuntu/word-count/input/file02\nhadoop fs -cat /user/ubuntu/word-count/input/*\n\n# build the jar (outside the machine to avoid permission issues)\ncd devops-lab/hadoop/example/map-reduce\n./gradlew clean build\n\n# run application\nhadoop jar /vagrant/example/map-reduce/build/libs/map-reduce.jar \\\n  /user/ubuntu/word-count/input \\\n  /user/ubuntu/word-count/output\n\n# check output\nhadoop fs -cat /user/ubuntu/word-count/output/part-r-00000\n\n# delete directory to run it again\nhadoop fs -rm -R /user/ubuntu/word-count/output\n\n# run sample job in a different queue\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  wordcount \\\n  -Dmapreduce.job.queuename=root.priority_queue \\\n  /user/ubuntu/word-count/input \\\n  /user/ubuntu/word-count/output\n\n# well known WARN issue\n# https://issues.apache.org/jira/browse/HDFS-10429\n\n\n\n\nBenchmarking MapReduce with TeraSort\n\n\n# generate random data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teragen 1000 random-data\n\n# run terasort benchmark\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  terasort random-data sorted-data\n\n# validate data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teravalidate sorted-data report\n\n# useful commands\nhadoop fs -ls -h -R .\nhadoop fs -rm -r random-data\nhadoop fs -cat random-data/part-m-00000\nhadoop fs -cat sorted-data/part-r-00000\n\n\n\n\nSpark\n\n\n\n\nSpark\n is an open-source cluster-computing framework\n\n\n\n\nTODO\n\n\nFlink\n\n\nTODO\n\n\nAvro\n\n\n\n\nAvro\n is a data serialization system\n\n\n\n\nTODO\n\n\nParquet\n\n\n\n\nParquet\n is a columnar storage format that can efficiently store nested data\n\n\n\n\nTODO\n\n\nFlume\n\n\nTODO\n\n\nSqoop\n\n\nTODO\n\n\nPig\n\n\nTODO\n\n\nHive\n\n\nTODO\n\n\nCrunch\n\n\nTODO\n\n\nHBase\n\n\nTODO\n\n\nOozie\n\n\n\n\nOozie\n is a workflow scheduler system to manage Hadoop jobs\n\n\n\n\nTODO\n\n\nGanglia\n\n\n\n\nGanglia\n is a monitoring system for Hadoop\n\n\n\n\nTODO\n\n\nZeppelin\n\n\nTODO\n\n\nKnox\n\n\nTODO", 
            "title": "Hadoop"
        }, 
        {
            "location": "/hadoop/#hadoop", 
            "text": "The following guide explains how to provision a Multi Node Hadoop Cluster locally and play with it. Checkout the  Vagrantfile  and the Vagrant  guide  for more details.", 
            "title": "Hadoop"
        }, 
        {
            "location": "/hadoop/#directory-structure", 
            "text": "All the commands are executed in this directory  cd hadoop  TODO", 
            "title": "Directory structure"
        }, 
        {
            "location": "/hadoop/#setup", 
            "text": "Requirements   Vagrant  VirtualBox   Import the script  source vagrant_hadoop.sh  Create and start a Multi Node Hadoop Cluster  hadoop-start  Note that the first time it could take a while  Access the cluster via ssh, check also the  /etc/hosts  file  vagrant ssh master\nssh hadoop@172.16.0.10 -i .data/hadoop_rsa\n\n# 3 nodes\nvagrant ssh node-1\nssh hadoop@172.16.0.101 -i .data/hadoop_rsa  Destroy the cluster  hadoop-destroy  Useful paths  # data\n/var/hadoop\n# logs\n/var/hadoop/log\n# (local) config\n/usr/local/hadoop/etc/hadoop\n# (hdfs) map-reduce history\n/mr-history/history/done_intermediate/hadoop\n# (hdfs) aggregated app logs\n/yarn/app/hadoop/logs/application_XXX", 
            "title": "Setup"
        }, 
        {
            "location": "/hadoop/#web-ui-links", 
            "text": "NameNode:  http://namenode:50070  NameNode metrics:  http://namenode:50070/jmx  ResourceManager:  http://resource-manager:8088  Log Level:  http://resource-manager:8088/logLevel  JVM stack traces:  http://resource-manager:8088/stacks  Web Application Proxy Server:  http://web-proxy:8100/proxy/application_XXX_0000  MapReduce Job History Server:  http://history:19888  DataNode/NodeManager (1):  http://node-1:8042/node  DataNode/NodeManager (2):  http://node-2:8042/node  DataNode/NodeManager (3):  http://node-3:8042/node", 
            "title": "Web UI links"
        }, 
        {
            "location": "/hadoop/#hdfs-and-mapreduce", 
            "text": "HDFS  is a distributed file system that provides high-throughput access to application data  YARN  is a framework for job scheduling and cluster resource management  MapReduce  is a YARN-based system for parallel processing of large data sets   Documentation   Hadoop v2.7.5  Untangling Apache Hadoop YARN  series", 
            "title": "HDFS and MapReduce"
        }, 
        {
            "location": "/hadoop/#hdfs-admin", 
            "text": "# filesystem statistics\nhdfs dfsadmin -report\n\n# filesystem check\nhdfs fsck /", 
            "title": "HDFS Admin"
        }, 
        {
            "location": "/hadoop/#mapreduce-wordcount-job", 
            "text": "# create base directory using hdfs\nhdfs dfs -mkdir -p /user/ubuntu\n\n# create example directory\nhadoop fs -mkdir -p /user/ubuntu/word-count/input\n\n# list directory\nhadoop fs -ls -h -R /\nhadoop fs -ls -h -R /user/ubuntu\n\n# create sample files\necho  Hello World Bye World    file01\necho  Hello Hadoop Goodbye Hadoop    file02\n\n# copy from local to hdfs\nhadoop fs -copyFromLocal file01 /user/ubuntu/word-count/input\nhadoop fs -put file02 /user/ubuntu/word-count/input\n\n# verify copied files\nhadoop fs -ls -h -R /user/ubuntu\nhadoop fs -cat /user/ubuntu/word-count/input/file01\nhadoop fs -cat /user/ubuntu/word-count/input/file02\nhadoop fs -cat /user/ubuntu/word-count/input/*\n\n# build the jar (outside the machine to avoid permission issues)\ncd devops-lab/hadoop/example/map-reduce\n./gradlew clean build\n\n# run application\nhadoop jar /vagrant/example/map-reduce/build/libs/map-reduce.jar \\\n  /user/ubuntu/word-count/input \\\n  /user/ubuntu/word-count/output\n\n# check output\nhadoop fs -cat /user/ubuntu/word-count/output/part-r-00000\n\n# delete directory to run it again\nhadoop fs -rm -R /user/ubuntu/word-count/output\n\n# run sample job in a different queue\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  wordcount \\\n  -Dmapreduce.job.queuename=root.priority_queue \\\n  /user/ubuntu/word-count/input \\\n  /user/ubuntu/word-count/output\n\n# well known WARN issue\n# https://issues.apache.org/jira/browse/HDFS-10429", 
            "title": "MapReduce WordCount Job"
        }, 
        {
            "location": "/hadoop/#benchmarking-mapreduce-with-terasort", 
            "text": "# generate random data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teragen 1000 random-data\n\n# run terasort benchmark\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  terasort random-data sorted-data\n\n# validate data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teravalidate sorted-data report\n\n# useful commands\nhadoop fs -ls -h -R .\nhadoop fs -rm -r random-data\nhadoop fs -cat random-data/part-m-00000\nhadoop fs -cat sorted-data/part-r-00000", 
            "title": "Benchmarking MapReduce with TeraSort"
        }, 
        {
            "location": "/hadoop/#spark", 
            "text": "Spark  is an open-source cluster-computing framework   TODO", 
            "title": "Spark"
        }, 
        {
            "location": "/hadoop/#flink", 
            "text": "TODO", 
            "title": "Flink"
        }, 
        {
            "location": "/hadoop/#avro", 
            "text": "Avro  is a data serialization system   TODO", 
            "title": "Avro"
        }, 
        {
            "location": "/hadoop/#parquet", 
            "text": "Parquet  is a columnar storage format that can efficiently store nested data   TODO", 
            "title": "Parquet"
        }, 
        {
            "location": "/hadoop/#flume", 
            "text": "TODO", 
            "title": "Flume"
        }, 
        {
            "location": "/hadoop/#sqoop", 
            "text": "TODO", 
            "title": "Sqoop"
        }, 
        {
            "location": "/hadoop/#pig", 
            "text": "TODO", 
            "title": "Pig"
        }, 
        {
            "location": "/hadoop/#hive", 
            "text": "TODO", 
            "title": "Hive"
        }, 
        {
            "location": "/hadoop/#crunch", 
            "text": "TODO", 
            "title": "Crunch"
        }, 
        {
            "location": "/hadoop/#hbase", 
            "text": "TODO", 
            "title": "HBase"
        }, 
        {
            "location": "/hadoop/#oozie", 
            "text": "Oozie  is a workflow scheduler system to manage Hadoop jobs   TODO", 
            "title": "Oozie"
        }, 
        {
            "location": "/hadoop/#ganglia", 
            "text": "Ganglia  is a monitoring system for Hadoop   TODO", 
            "title": "Ganglia"
        }, 
        {
            "location": "/hadoop/#zeppelin", 
            "text": "TODO", 
            "title": "Zeppelin"
        }, 
        {
            "location": "/hadoop/#knox", 
            "text": "TODO", 
            "title": "Knox"
        }, 
        {
            "location": "/cassandra/", 
            "text": "Cassandra\n\n\nTODO\n\n\nRequirements\n\n\n\n\nDocker", 
            "title": "Cassandra"
        }, 
        {
            "location": "/cassandra/#cassandra", 
            "text": "TODO  Requirements   Docker", 
            "title": "Cassandra"
        }, 
        {
            "location": "/zookeeper/", 
            "text": "Zookeeper\n\n\nTODO", 
            "title": "Zookeeper"
        }, 
        {
            "location": "/zookeeper/#zookeeper", 
            "text": "TODO", 
            "title": "Zookeeper"
        }, 
        {
            "location": "/kafka/", 
            "text": "Kafka\n\n\nTODO", 
            "title": "Kafka"
        }, 
        {
            "location": "/kafka/#kafka", 
            "text": "TODO", 
            "title": "Kafka"
        }, 
        {
            "location": "/other/", 
            "text": "Other\n\n\nDocker\n\n\nDocker is an open platform for developers and sysadmins to build, ship, and run distributed applications.\n\n\nOffical documentation\n\n\n\n\nDocker\n\n\n\n\nBasic Docker commands\n\n\nTODO\n\n\nTODO\n\n\n\n\nDocker Machine\n\n\nTODO\n\n\nTODO\n\n\n\n\nVagrant\n\n\nVagrant is a tool for building and managing virtual machine environments in a single workflow.\n\n\nOffical documentation\n\n\n\n\nVagrant\n\n\nVirtualBox\n\n\n\n\nBasic Vagrant commands\n\n\nSetup project creating a Vagrantfile\n\n\nvagrant init\n\n\n\n\nBoot and connect to the default virtual machine\n\n\nvagrant up\nvagrant status\nvagrant ssh\n\n\n\n\nUseful commands\n\n\n# shut down gracefully\nvagrant halt\n\n# reload (halt + up) + re-provision\nvagrant reload --provision\n\n# update box\nvagrant box update\n\n# delete virtual machine without prompt\nvagrant destory -f\n\n\n\n\nMkDocs\n\n\nMkDocs is a static site generator.\n\n\nOffical documentation\n\n\n\n\nMkDocs\n\n\n\n\nBasic MkDocs commands\n\n\nInstall\n\n\npip install mkdocs\n\n\n\n\nSetup in current directory\n\n\nmkdocs new .\n\n\n\n\nStart dev server with hot reload on \nhttp://127.0.0.1:8000\n\n\nmkdocs serve\n\n\n\n\nBuild static site\n\n\nmkdocs build --clean\n\n\n\n\nDeploy to github\n\n\nmkdocs gh-deploy\n\n\n\n\nSDKMAN!\n\n\nSDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems.\n\n\nOffical documentation\n\n\n\n\nSDKMAN!\n\n\n\n\nSetup\n\n\ncurl -s \nhttps://get.sdkman.io\n | bash\nsource \n$HOME/.sdkman/bin/sdkman-init.sh\n\nsdk version\n\n\n\n\nGradle\n\n\nSetup\n\n\nsdk list gradle\nsdk install gradle 4.4.1\ngradle -version\n\n\n\n\nCreate Gradle project\n\n\nmkdir -p PROJECT_NAME \n cd $_\ngradle init --type java-library\n\n./gradlew clean build\n\n\n\n\nBooks\n\n\n\n\nDesigning Data-Intensive Applications\n (2017) by Martin Kleppmann\n\n\nHadoop: The Definitive Guide\n (4th)(2015) by Tom White\n\n\nSpark in Action\n (2016) by Petar Ze\u010devi\u0107 and Marko Bona\u0107i\n\n\nCassandra: The Definitive Guide\n (4th)(2016) By Eben Hewitt, Jeff Carpenter\n\n\nKafka: The Definitive Guide\n (2017) By Gwen Shapira, Neha Narkhede, Todd Palino", 
            "title": "Other"
        }, 
        {
            "location": "/other/#other", 
            "text": "", 
            "title": "Other"
        }, 
        {
            "location": "/other/#docker", 
            "text": "Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications.  Offical documentation   Docker", 
            "title": "Docker"
        }, 
        {
            "location": "/other/#basic-docker-commands", 
            "text": "TODO  TODO", 
            "title": "Basic Docker commands"
        }, 
        {
            "location": "/other/#docker-machine", 
            "text": "TODO  TODO", 
            "title": "Docker Machine"
        }, 
        {
            "location": "/other/#vagrant", 
            "text": "Vagrant is a tool for building and managing virtual machine environments in a single workflow.  Offical documentation   Vagrant  VirtualBox", 
            "title": "Vagrant"
        }, 
        {
            "location": "/other/#basic-vagrant-commands", 
            "text": "Setup project creating a Vagrantfile  vagrant init  Boot and connect to the default virtual machine  vagrant up\nvagrant status\nvagrant ssh  Useful commands  # shut down gracefully\nvagrant halt\n\n# reload (halt + up) + re-provision\nvagrant reload --provision\n\n# update box\nvagrant box update\n\n# delete virtual machine without prompt\nvagrant destory -f", 
            "title": "Basic Vagrant commands"
        }, 
        {
            "location": "/other/#mkdocs", 
            "text": "MkDocs is a static site generator.  Offical documentation   MkDocs", 
            "title": "MkDocs"
        }, 
        {
            "location": "/other/#basic-mkdocs-commands", 
            "text": "Install  pip install mkdocs  Setup in current directory  mkdocs new .  Start dev server with hot reload on  http://127.0.0.1:8000  mkdocs serve  Build static site  mkdocs build --clean  Deploy to github  mkdocs gh-deploy", 
            "title": "Basic MkDocs commands"
        }, 
        {
            "location": "/other/#sdkman", 
            "text": "SDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems.  Offical documentation   SDKMAN!   Setup  curl -s  https://get.sdkman.io  | bash\nsource  $HOME/.sdkman/bin/sdkman-init.sh \nsdk version", 
            "title": "SDKMAN!"
        }, 
        {
            "location": "/other/#gradle", 
            "text": "Setup  sdk list gradle\nsdk install gradle 4.4.1\ngradle -version  Create Gradle project  mkdir -p PROJECT_NAME   cd $_\ngradle init --type java-library\n\n./gradlew clean build", 
            "title": "Gradle"
        }, 
        {
            "location": "/other/#books", 
            "text": "Designing Data-Intensive Applications  (2017) by Martin Kleppmann  Hadoop: The Definitive Guide  (4th)(2015) by Tom White  Spark in Action  (2016) by Petar Ze\u010devi\u0107 and Marko Bona\u0107i  Cassandra: The Definitive Guide  (4th)(2016) By Eben Hewitt, Jeff Carpenter  Kafka: The Definitive Guide  (2017) By Gwen Shapira, Neha Narkhede, Todd Palino", 
            "title": "Books"
        }
    ]
}