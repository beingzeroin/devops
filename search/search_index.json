{
    "docs": [
        {
            "location": "/", 
            "text": "Provision Tools\n\n\nA collection of Docker and Vagrant images mainly to provision distributed systems for local development and quick prototyping.\n\n\nDocumentations\n\n\n\n\nAnsible\n\n\nHadoop and Spark\n\n\nCassandra\n\n\nZookeeper\n\n\nKafka\n\n\nOther", 
            "title": "Home"
        }, 
        {
            "location": "/#provision-tools", 
            "text": "A collection of Docker and Vagrant images mainly to provision distributed systems for local development and quick prototyping.  Documentations   Ansible  Hadoop and Spark  Cassandra  Zookeeper  Kafka  Other", 
            "title": "Provision Tools"
        }, 
        {
            "location": "/ansible/", 
            "text": "Ansible\n\n\nAnsible is an open source automation platform that can help with config management, deployment and task automation.\n\n\nDocumentation\n\n\n\n\nAnsible\n\n\nTutorial\n\n\nPlaybook example\n\n\n\n\nRequirement\n\n\n\n\nVagrant\n\n\nVirtualBox\n\n\n\n\nThe following guide explains how to provision Ansible locally and play with it. Checkout the \nVagrantfile\n and the Vagrant \nguide\n for more details.\n\n\nDirectory structure\n\n\nAll the commands are executed in this directory \ncd ansible\n\n\nansible/\n\u251c\u2500\u2500 .share\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ssh\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ansible_rsa\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 ansible_rsa.pub\n\u251c\u2500\u2500 Vagrantfile\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 group_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 host_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hosts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 roles\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 defaults\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 handlers\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 motd.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 motd\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 vars\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 site.yml\n\u251c\u2500\u2500 setup_ansible.sh\n\u2514\u2500\u2500 setup_share.sh\n\n\n\n\nSetup\n\n\nThe first time \nonly\n, you have to setup the shared folders and generate the ssh key needed by ansible to access all nodes executing\n\n\n./setup_share.sh\n\n\n\n\nFrom now on start the boxes with\n\n\nvagrant up\n\n\n\n\nNote that the first time it could take a while\n\n\nVerify status of the boxes with\n\n\nvagrant status\n\n\n\n\nVerify access to the boxes with\n\n\nvagrant ssh ansible\nvagrant ssh node-1\n\n\n\n\nFrom inside the boxes you should be able to communicate with the others\n\n\nping ansible.local\nping ip-192-168-100-11.local\nping 192.168.100.12\n\n\n\n\nThe following paths are shared with the boxes\n\n\n\n\n/vagrant\n provision-tool\n\n\n/local\n host $HOME\n\n\n/ansible\n data \n(ansible only)\n\n\n/data\n .share \n(node only)\n\n\n\n\nAd-Hoc Commands\n\n\nAccess the ansible box with\n\n\nvagrant ssh ansible\n\n\n\n\nBelow a list of examples\n\n\n\n# ping all nodes (default inventory /etc/ansible/hosts)\nansible all -m ping\nansible ansible -m ping\nansible cluster -m ping\n\n# ping all nodes (specify inventory)\nansible all -i \n/vagrant/data/hosts\n -m ping\n\n# gathering facts\nansible all -m setup\nansible ansible -m setup\n\n# specify host and user\nansible ip-192-168-100-11.local -m ping -u vagrant\n\n# execute command\nansible all -a \n/bin/echo hello\n\nansible all -a \nuptime\n\nansible all -a \n/bin/date\n\n# do NOT reboot vagrant through ansible (use vagrant reload)\nansible cluster -a \n/sbin/reboot\n --become\n\n# shell module\nansible all -m shell -a \npwd\n\n# be carefull to quotes\nansible all -m shell -a 'echo $HOME'\n\n# update \n upgrade\nansible all -m apt -a \nupdate_cache=yes upgrade=dist\n --become\n# restart after upgrade\nvagrant reload\n# install package\nansible all -m apt -a \nname=tree state=present\n --become\n\n\n\n\nPlaybooks\n\n\nAccess the ansible box with\n\n\nvagrant ssh ansible\n\n\n\n\nBelow a list of examples\n\n\n# test uptime on all node\nansible-playbook /ansible/site.yml --tags=test --verbose\n\n# update \n upgrade only cluster nodes\nansible-playbook /ansible/site.yml -t package --skip-tags=java --verbose\n\n# install packages on cluster nodes\nansible-playbook /ansible/site.yml -t package --verbose\n\n# run common task on cluster node\nansible-playbook /ansible/site.yml -t common\n\n# setup docker\nansible-playbook /ansible/site.yml -t docker\n# test docker\nvagrant ssh node-1\nsudo -i -u docker\ndocker ps -a\n\n# custom banner\nansible-playbook /ansible/site.yml -t motd\n\n# setup all infrastructure at once\nansible-playbook /ansible/site.yml\n\n# dry run\nansible-playbook -i /ansible/hosts /ansible/site.yml --check --diff", 
            "title": "Ansible"
        }, 
        {
            "location": "/ansible/#ansible", 
            "text": "Ansible is an open source automation platform that can help with config management, deployment and task automation.  Documentation   Ansible  Tutorial  Playbook example   Requirement   Vagrant  VirtualBox   The following guide explains how to provision Ansible locally and play with it. Checkout the  Vagrantfile  and the Vagrant  guide  for more details.", 
            "title": "Ansible"
        }, 
        {
            "location": "/ansible/#directory-structure", 
            "text": "All the commands are executed in this directory  cd ansible  ansible/\n\u251c\u2500\u2500 .share\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node-3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ssh\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ansible_rsa\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 ansible_rsa.pub\n\u251c\u2500\u2500 Vagrantfile\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 group_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 host_vars\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hosts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 roles\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 defaults\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 handlers\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 motd.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 motd\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 vars\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 meta\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 site.yml\n\u251c\u2500\u2500 setup_ansible.sh\n\u2514\u2500\u2500 setup_share.sh", 
            "title": "Directory structure"
        }, 
        {
            "location": "/ansible/#setup", 
            "text": "The first time  only , you have to setup the shared folders and generate the ssh key needed by ansible to access all nodes executing  ./setup_share.sh  From now on start the boxes with  vagrant up  Note that the first time it could take a while  Verify status of the boxes with  vagrant status  Verify access to the boxes with  vagrant ssh ansible\nvagrant ssh node-1  From inside the boxes you should be able to communicate with the others  ping ansible.local\nping ip-192-168-100-11.local\nping 192.168.100.12  The following paths are shared with the boxes   /vagrant  provision-tool  /local  host $HOME  /ansible  data  (ansible only)  /data  .share  (node only)", 
            "title": "Setup"
        }, 
        {
            "location": "/ansible/#ad-hoc-commands", 
            "text": "Access the ansible box with  vagrant ssh ansible  Below a list of examples  \n# ping all nodes (default inventory /etc/ansible/hosts)\nansible all -m ping\nansible ansible -m ping\nansible cluster -m ping\n\n# ping all nodes (specify inventory)\nansible all -i  /vagrant/data/hosts  -m ping\n\n# gathering facts\nansible all -m setup\nansible ansible -m setup\n\n# specify host and user\nansible ip-192-168-100-11.local -m ping -u vagrant\n\n# execute command\nansible all -a  /bin/echo hello \nansible all -a  uptime \nansible all -a  /bin/date \n# do NOT reboot vagrant through ansible (use vagrant reload)\nansible cluster -a  /sbin/reboot  --become\n\n# shell module\nansible all -m shell -a  pwd \n# be carefull to quotes\nansible all -m shell -a 'echo $HOME'\n\n# update   upgrade\nansible all -m apt -a  update_cache=yes upgrade=dist  --become\n# restart after upgrade\nvagrant reload\n# install package\nansible all -m apt -a  name=tree state=present  --become", 
            "title": "Ad-Hoc Commands"
        }, 
        {
            "location": "/ansible/#playbooks", 
            "text": "Access the ansible box with  vagrant ssh ansible  Below a list of examples  # test uptime on all node\nansible-playbook /ansible/site.yml --tags=test --verbose\n\n# update   upgrade only cluster nodes\nansible-playbook /ansible/site.yml -t package --skip-tags=java --verbose\n\n# install packages on cluster nodes\nansible-playbook /ansible/site.yml -t package --verbose\n\n# run common task on cluster node\nansible-playbook /ansible/site.yml -t common\n\n# setup docker\nansible-playbook /ansible/site.yml -t docker\n# test docker\nvagrant ssh node-1\nsudo -i -u docker\ndocker ps -a\n\n# custom banner\nansible-playbook /ansible/site.yml -t motd\n\n# setup all infrastructure at once\nansible-playbook /ansible/site.yml\n\n# dry run\nansible-playbook -i /ansible/hosts /ansible/site.yml --check --diff", 
            "title": "Playbooks"
        }, 
        {
            "location": "/hadoop-spark/", 
            "text": "Hadoop and Spark\n\n\n\n\nHDFS\n A distributed file system that provides high-throughput access to application data\n\n\nYARN\n A framework for job scheduling and cluster resource management\n\n\nMapReduce\n A YARN-based system for parallel processing of large data sets\n\n\nSpark\n An open-source cluster-computing framework\n\n\nAvro\n A data serialization system\n\n\nParquet\n A columnar storage format that can efficiently store nested data\n\n\nOozie\n A workflow scheduler system to manage Hadoop jobs\n\n\nGanglia\n A monitoring system for Hadoop\n\n\n\n\nOffical documentation\n\n\n\n\nHadoop\n\n\nParquet\n\n\nOozie\n\n\nGanglia\n\n\n\n\nRequirement\n\n\n\n\nVagrant\n\n\nVirtualBox\n\n\n\n\nThe following guide explains how to provision a Single Node Hadoop Cluster locally and play with it. Checkout the \nVagrantfile\n and the Vagrant \nguide\n for more details.\n\n\nDirectory structure\n\n\nAll the commands are executed in this directory \ncd hadoop-spark\n\n\nhadoop-spark/\n\u251c\u2500\u2500 example\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 map-reduce\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 build\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 ...\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 libs\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u00a0\u00a0 \u2514\u2500\u2500 map-reduce.jar\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 build.gradle\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 gradlew\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 src\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 main\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 java\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0     \u2514\u2500\u2500 com\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0         \u2514\u2500\u2500 github\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0             \u2514\u2500\u2500 niqdev\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0                 \u251c\u2500\u2500 IntSumReducer.java\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0                 \u251c\u2500\u2500 TokenizerMapper.java\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0                 \u2514\u2500\u2500 WordCount.java\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 test\n\u2502\u00a0\u00a0             \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 file\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hadoop-core-site.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hadoop-hdfs-site.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mapred-site.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ssh-config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 yarn-site.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 script\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 bootstrap.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_all.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_hadoop.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_java.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_spark.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_user.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 start_hadoop.sh\n\u2514\u2500\u2500 Vagrantfile\n\n\n\n\nWeb UI\n\n\n\n\nnamenode \nhttp://localhost:50070\n\n\nresource manager \nhttp://localhost:8088\n\n\nhistory server \nhttp://localhost:19888\n\n\nset log level temporarily \nhttp://localhost:8088/logLevel\n\n\nJVM stack traces \nhttp://localhost:8088/stacks\n\n\nnamenode metrics \nhttp://localhost:50070/jmx\n\n\n\n\nSetup\n\n\nStart the box and verify the status\n\n\nvagrant up\nvagrant status\n\n\n\n\nNote that the first time it could take a while\n\n\nAccess the box\n\n\nvagrant ssh\n\n\n\n\nUseful paths\n\n\n# logs\n/usr/local/hadoop/logs\n# data\n/var/hadoop\n# config\n/usr/local/hadoop/etc/hadoop\n\n\n\n\nHDFS\n\n\nAdmin\n\n\n# filesystem statistics\nhdfs dfsadmin -report\n\n# filesystem check\nhdfs fsck /\n\n\n\n\nExample\n\n\nMapReduce WordCount Job\n\n\n# create base directory using hdfs\nhdfs dfs -mkdir -p /user/ubuntu\n\n# create example directory\nhadoop fs -mkdir -p /user/ubuntu/word-count/input\n\n# list directory\nhadoop fs -ls -h -R /\nhadoop fs -ls -h -R /user/ubuntu\n\n# create sample files\necho \nHello World Bye World\n \n file01\necho \nHello Hadoop Goodbye Hadoop\n \n file02\n\n# copy from local to hdfs\nhadoop fs -copyFromLocal file01 /user/ubuntu/word-count/input\nhadoop fs -put file02 /user/ubuntu/word-count/input\n\n# verify copied files\nhadoop fs -ls -h -R /user/ubuntu\nhadoop fs -cat /user/ubuntu/word-count/input/file01\nhadoop fs -cat /user/ubuntu/word-count/input/file02\nhadoop fs -cat /user/ubuntu/word-count/input/*\n\n# build the jar (outside the machine to avoid permission issues)\ncd provision-tools/hadoop-spark/example/map-reduce\n./gradlew clean build\n\n# run application\nhadoop jar /vagrant/example/map-reduce/build/libs/map-reduce.jar \\\n  /user/ubuntu/word-count/input \\\n  /user/ubuntu/word-count/output\n\n# check output\nhadoop fs -cat /user/ubuntu/word-count/output/part-r-00000\n\n# delete directory to run it again\nhadoop fs -rm -R /user/ubuntu/word-count/output\n\n\n\n\nBenchmarking MapReduce with TeraSort\n\n\n# generate random data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teragen 1000 random-data\n\n# run terasort benchmark\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  terasort random-data sorted-data\n\n# validate data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teravalidate sorted-data report\n\n# useful commands\nhadoop fs -ls -h -R .\nhadoop fs -rm -r random-data\nhadoop fs -cat random-data/part-m-00000\nhadoop fs -cat sorted-data/part-r-00000\n\n\n\n\nSpark Job\n\n\nTODO", 
            "title": "Hadoop and Spark"
        }, 
        {
            "location": "/hadoop-spark/#hadoop-and-spark", 
            "text": "HDFS  A distributed file system that provides high-throughput access to application data  YARN  A framework for job scheduling and cluster resource management  MapReduce  A YARN-based system for parallel processing of large data sets  Spark  An open-source cluster-computing framework  Avro  A data serialization system  Parquet  A columnar storage format that can efficiently store nested data  Oozie  A workflow scheduler system to manage Hadoop jobs  Ganglia  A monitoring system for Hadoop   Offical documentation   Hadoop  Parquet  Oozie  Ganglia   Requirement   Vagrant  VirtualBox   The following guide explains how to provision a Single Node Hadoop Cluster locally and play with it. Checkout the  Vagrantfile  and the Vagrant  guide  for more details.", 
            "title": "Hadoop and Spark"
        }, 
        {
            "location": "/hadoop-spark/#directory-structure", 
            "text": "All the commands are executed in this directory  cd hadoop-spark  hadoop-spark/\n\u251c\u2500\u2500 example\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 map-reduce\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 build\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 ...\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 libs\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u00a0\u00a0 \u2514\u2500\u2500 map-reduce.jar\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 build.gradle\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 gradlew\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 src\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 main\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 java\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0     \u2514\u2500\u2500 com\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0         \u2514\u2500\u2500 github\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0             \u2514\u2500\u2500 niqdev\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0                 \u251c\u2500\u2500 IntSumReducer.java\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0                 \u251c\u2500\u2500 TokenizerMapper.java\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0                 \u2514\u2500\u2500 WordCount.java\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 test\n\u2502\u00a0\u00a0             \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 file\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hadoop-core-site.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hadoop-hdfs-site.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mapred-site.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ssh-config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 yarn-site.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 script\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 bootstrap.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_all.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_hadoop.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_java.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_spark.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup_user.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 start_hadoop.sh\n\u2514\u2500\u2500 Vagrantfile", 
            "title": "Directory structure"
        }, 
        {
            "location": "/hadoop-spark/#web-ui", 
            "text": "namenode  http://localhost:50070  resource manager  http://localhost:8088  history server  http://localhost:19888  set log level temporarily  http://localhost:8088/logLevel  JVM stack traces  http://localhost:8088/stacks  namenode metrics  http://localhost:50070/jmx", 
            "title": "Web UI"
        }, 
        {
            "location": "/hadoop-spark/#setup", 
            "text": "Start the box and verify the status  vagrant up\nvagrant status  Note that the first time it could take a while  Access the box  vagrant ssh  Useful paths  # logs\n/usr/local/hadoop/logs\n# data\n/var/hadoop\n# config\n/usr/local/hadoop/etc/hadoop", 
            "title": "Setup"
        }, 
        {
            "location": "/hadoop-spark/#hdfs", 
            "text": "", 
            "title": "HDFS"
        }, 
        {
            "location": "/hadoop-spark/#admin", 
            "text": "# filesystem statistics\nhdfs dfsadmin -report\n\n# filesystem check\nhdfs fsck /", 
            "title": "Admin"
        }, 
        {
            "location": "/hadoop-spark/#example", 
            "text": "", 
            "title": "Example"
        }, 
        {
            "location": "/hadoop-spark/#mapreduce-wordcount-job", 
            "text": "# create base directory using hdfs\nhdfs dfs -mkdir -p /user/ubuntu\n\n# create example directory\nhadoop fs -mkdir -p /user/ubuntu/word-count/input\n\n# list directory\nhadoop fs -ls -h -R /\nhadoop fs -ls -h -R /user/ubuntu\n\n# create sample files\necho  Hello World Bye World    file01\necho  Hello Hadoop Goodbye Hadoop    file02\n\n# copy from local to hdfs\nhadoop fs -copyFromLocal file01 /user/ubuntu/word-count/input\nhadoop fs -put file02 /user/ubuntu/word-count/input\n\n# verify copied files\nhadoop fs -ls -h -R /user/ubuntu\nhadoop fs -cat /user/ubuntu/word-count/input/file01\nhadoop fs -cat /user/ubuntu/word-count/input/file02\nhadoop fs -cat /user/ubuntu/word-count/input/*\n\n# build the jar (outside the machine to avoid permission issues)\ncd provision-tools/hadoop-spark/example/map-reduce\n./gradlew clean build\n\n# run application\nhadoop jar /vagrant/example/map-reduce/build/libs/map-reduce.jar \\\n  /user/ubuntu/word-count/input \\\n  /user/ubuntu/word-count/output\n\n# check output\nhadoop fs -cat /user/ubuntu/word-count/output/part-r-00000\n\n# delete directory to run it again\nhadoop fs -rm -R /user/ubuntu/word-count/output", 
            "title": "MapReduce WordCount Job"
        }, 
        {
            "location": "/hadoop-spark/#benchmarking-mapreduce-with-terasort", 
            "text": "# generate random data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teragen 1000 random-data\n\n# run terasort benchmark\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  terasort random-data sorted-data\n\n# validate data\nhadoop jar \\\n  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \\\n  teravalidate sorted-data report\n\n# useful commands\nhadoop fs -ls -h -R .\nhadoop fs -rm -r random-data\nhadoop fs -cat random-data/part-m-00000\nhadoop fs -cat sorted-data/part-r-00000", 
            "title": "Benchmarking MapReduce with TeraSort"
        }, 
        {
            "location": "/hadoop-spark/#spark-job", 
            "text": "TODO", 
            "title": "Spark Job"
        }, 
        {
            "location": "/cassandra/", 
            "text": "Cassandra\n\n\nTODO\n\n\nRequirements\n\n\n\n\nDocker", 
            "title": "Cassandra"
        }, 
        {
            "location": "/cassandra/#cassandra", 
            "text": "TODO  Requirements   Docker", 
            "title": "Cassandra"
        }, 
        {
            "location": "/zookeeper/", 
            "text": "Zookeeper\n\n\nTODO", 
            "title": "Zookeeper"
        }, 
        {
            "location": "/zookeeper/#zookeeper", 
            "text": "TODO", 
            "title": "Zookeeper"
        }, 
        {
            "location": "/kafka/", 
            "text": "Kafka\n\n\nTODO", 
            "title": "Kafka"
        }, 
        {
            "location": "/kafka/#kafka", 
            "text": "TODO", 
            "title": "Kafka"
        }, 
        {
            "location": "/other/", 
            "text": "Other\n\n\nDocker\n\n\nDocker is an open platform for developers and sysadmins to build, ship, and run distributed applications.\n\n\nOffical documentation\n\n\n\n\nDocker\n\n\n\n\nBasic Docker commands\n\n\nTODO\n\n\nTODO\n\n\n\n\nDocker Machine\n\n\nTODO\n\n\nTODO\n\n\n\n\nVagrant\n\n\nVagrant is a tool for building and managing virtual machine environments in a single workflow.\n\n\nOffical documentation\n\n\n\n\nVagrant\n\n\nVirtualBox\n\n\n\n\nBasic Vagrant commands\n\n\nSetup project creating a Vagrantfile\n\n\nvagrant init\n\n\n\n\nBoot and connect to the default virtual machine\n\n\nvagrant up\nvagrant status\nvagrant ssh\n\n\n\n\nUseful commands\n\n\n# shut down gracefully\nvagrant halt\n\n# reload (halt + up) + re-provision\nvagrant reload --provision\n\n# update box\nvagrant box update\n\n# delete virtual machine without prompt\nvagrant destory -f\n\n\n\n\nMkDocs\n\n\nMkDocs is a static site generator.\n\n\nOffical documentation\n\n\n\n\nMkDocs\n\n\n\n\nBasic MkDocs commands\n\n\nInstall\n\n\npip install mkdocs\n\n\n\n\nSetup in current directory\n\n\nmkdocs new .\n\n\n\n\nStart dev server with hot reload on \nhttp://127.0.0.1:8000\n\n\nmkdocs serve\n\n\n\n\nBuild static site\n\n\nmkdocs build --clean\n\n\n\n\nDeploy to github\n\n\nmkdocs gh-deploy\n\n\n\n\nSDKMAN!\n\n\nSDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems.\n\n\nOffical documentation\n\n\n\n\nSDKMAN!\n\n\n\n\nSetup\n\n\ncurl -s \nhttps://get.sdkman.io\n | bash\nsource \n$HOME/.sdkman/bin/sdkman-init.sh\n\nsdk version\n\n\n\n\nGradle\n\n\nSetup\n\n\nsdk list gradle\nsdk install gradle 4.4.1\ngradle -version\n\n\n\n\nCreate Gradle project\n\n\nmkdir -p PROJECT_NAME \n cd $_\ngradle init --type java-library\n\n./gradlew clean build\n\n\n\n\nBooks\n\n\n\n\nDesigning Data-Intensive Applications\n (2017) by Martin Kleppmann\n\n\nHadoop: The Definitive Guide\n (4th)(2015) by Tom White\n\n\nSpark in Action\n (2016) by Petar Ze\u010devi\u0107 and Marko Bona\u0107i\n\n\nCassandra: The Definitive Guide\n (4th)(2016) By Eben Hewitt, Jeff Carpenter\n\n\nKafka: The Definitive Guide\n (2017) By Gwen Shapira, Neha Narkhede, Todd Palino", 
            "title": "Other"
        }, 
        {
            "location": "/other/#other", 
            "text": "", 
            "title": "Other"
        }, 
        {
            "location": "/other/#docker", 
            "text": "Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications.  Offical documentation   Docker", 
            "title": "Docker"
        }, 
        {
            "location": "/other/#basic-docker-commands", 
            "text": "TODO  TODO", 
            "title": "Basic Docker commands"
        }, 
        {
            "location": "/other/#docker-machine", 
            "text": "TODO  TODO", 
            "title": "Docker Machine"
        }, 
        {
            "location": "/other/#vagrant", 
            "text": "Vagrant is a tool for building and managing virtual machine environments in a single workflow.  Offical documentation   Vagrant  VirtualBox", 
            "title": "Vagrant"
        }, 
        {
            "location": "/other/#basic-vagrant-commands", 
            "text": "Setup project creating a Vagrantfile  vagrant init  Boot and connect to the default virtual machine  vagrant up\nvagrant status\nvagrant ssh  Useful commands  # shut down gracefully\nvagrant halt\n\n# reload (halt + up) + re-provision\nvagrant reload --provision\n\n# update box\nvagrant box update\n\n# delete virtual machine without prompt\nvagrant destory -f", 
            "title": "Basic Vagrant commands"
        }, 
        {
            "location": "/other/#mkdocs", 
            "text": "MkDocs is a static site generator.  Offical documentation   MkDocs", 
            "title": "MkDocs"
        }, 
        {
            "location": "/other/#basic-mkdocs-commands", 
            "text": "Install  pip install mkdocs  Setup in current directory  mkdocs new .  Start dev server with hot reload on  http://127.0.0.1:8000  mkdocs serve  Build static site  mkdocs build --clean  Deploy to github  mkdocs gh-deploy", 
            "title": "Basic MkDocs commands"
        }, 
        {
            "location": "/other/#sdkman", 
            "text": "SDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems.  Offical documentation   SDKMAN!   Setup  curl -s  https://get.sdkman.io  | bash\nsource  $HOME/.sdkman/bin/sdkman-init.sh \nsdk version", 
            "title": "SDKMAN!"
        }, 
        {
            "location": "/other/#gradle", 
            "text": "Setup  sdk list gradle\nsdk install gradle 4.4.1\ngradle -version  Create Gradle project  mkdir -p PROJECT_NAME   cd $_\ngradle init --type java-library\n\n./gradlew clean build", 
            "title": "Gradle"
        }, 
        {
            "location": "/other/#books", 
            "text": "Designing Data-Intensive Applications  (2017) by Martin Kleppmann  Hadoop: The Definitive Guide  (4th)(2015) by Tom White  Spark in Action  (2016) by Petar Ze\u010devi\u0107 and Marko Bona\u0107i  Cassandra: The Definitive Guide  (4th)(2016) By Eben Hewitt, Jeff Carpenter  Kafka: The Definitive Guide  (2017) By Gwen Shapira, Neha Narkhede, Todd Palino", 
            "title": "Books"
        }
    ]
}